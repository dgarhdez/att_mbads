{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2: Data Manipulation and Aggregations\n",
    "\n",
    "In this session, we'll dive deeper into Polars' data manipulation capabilities. You'll learn how to filter, transform, aggregate, and join data using the powerful expression API.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this session, you will be able to:\n",
    "1. Filter rows using boolean expressions\n",
    "2. Create columns with conditional logic\n",
    "3. Perform groupby aggregations\n",
    "4. Handle missing data\n",
    "5. Join and concatenate DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Load our datasets\n",
    "orders = pl.read_csv(\"data/ecommerce_orders.csv\")\n",
    "customers = pl.read_csv(\"data/customers.csv\")\n",
    "\n",
    "print(f\"Orders: {orders.shape}\")\n",
    "print(f\"Customers: {customers.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Filtering Rows with `filter()`\n",
    "\n",
    "The `filter()` method lets you select rows based on conditions.\n",
    "\n",
    "### 1.1 Simple Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter orders over $100\n",
    "large_orders = orders.filter(pl.col(\"total_amount\") > 100)\n",
    "print(f\"Orders over $100: {large_orders.height}\")\n",
    "large_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by string equality\n",
    "electronics = orders.filter(pl.col(\"category\") == \"Electronics\")\n",
    "print(f\"Electronics orders: {electronics.height}\")\n",
    "electronics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Multiple Conditions\n",
    "\n",
    "Use `&` (and) and `|` (or) to combine conditions. **Important**: Wrap each condition in parentheses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electronics orders over $500\n",
    "big_electronics = orders.filter(\n",
    "    (pl.col(\"category\") == \"Electronics\") & \n",
    "    (pl.col(\"total_amount\") > 500)\n",
    ")\n",
    "print(f\"Big electronics orders: {big_electronics.height}\")\n",
    "big_electronics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completed or shipped orders\n",
    "fulfilled = orders.filter(\n",
    "    (pl.col(\"status\") == \"completed\") | \n",
    "    (pl.col(\"status\") == \"shipped\")\n",
    ")\n",
    "print(f\"Fulfilled orders: {fulfilled.height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: use is_in() for multiple values\n",
    "fulfilled = orders.filter(\n",
    "    pl.col(\"status\").is_in([\"completed\", \"shipped\"])\n",
    ")\n",
    "print(f\"Fulfilled orders: {fulfilled.height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 String Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Products containing \"phone\" (case-insensitive)\n",
    "phones = orders.filter(\n",
    "    pl.col(\"product_name\").str.to_lowercase().str.contains(\"phone\")\n",
    ")\n",
    "phones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Products starting with \"S\"\n",
    "s_products = orders.filter(\n",
    "    pl.col(\"product_name\").str.starts_with(\"S\")\n",
    ")\n",
    "s_products.select(\"product_name\").unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Comparison: Filtering\n",
    "\n",
    "| Operation | Pandas | Polars |\n",
    "|-----------|--------|--------|\n",
    "| Simple filter | `df[df[\"col\"] > 100]` | `df.filter(pl.col(\"col\") > 100)` |\n",
    "| Multiple conditions | `df[(df[\"a\"] > 1) & (df[\"b\"] < 5)]` | `df.filter((pl.col(\"a\") > 1) & (pl.col(\"b\") < 5))` |\n",
    "| Is in list | `df[df[\"col\"].isin([\"a\", \"b\"])]` | `df.filter(pl.col(\"col\").is_in([\"a\", \"b\"]))` |\n",
    "| Contains string | `df[df[\"col\"].str.contains(\"x\")]` | `df.filter(pl.col(\"col\").str.contains(\"x\"))` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Columns with `with_columns()` and `alias()`\n",
    "\n",
    "### 2.1 Basic Column Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add calculated columns\n",
    "orders_enhanced = orders.with_columns(\n",
    "    # Revenue per item\n",
    "    (pl.col(\"total_amount\") / pl.col(\"quantity\")).alias(\"revenue_per_item\"),\n",
    "    \n",
    "    # Discount amount in dollars\n",
    "    (pl.col(\"unit_price\") * pl.col(\"quantity\") * pl.col(\"discount\")).alias(\"discount_amount\")\n",
    ")\n",
    "\n",
    "orders_enhanced.select(\n",
    "    \"product_name\", \"quantity\", \"total_amount\", \"revenue_per_item\", \"discount_amount\"\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Pandas Comparison: Creating Columns\n\n| Operation | Pandas | Polars |\n|-----------|--------|--------|\n| Add single column | `df[\"new\"] = df[\"a\"] + df[\"b\"]` | `df.with_columns((pl.col(\"a\") + pl.col(\"b\")).alias(\"new\"))` |\n| Add multiple columns | `df.assign(a=..., b=...)` | `df.with_columns(expr1, expr2)` |\n| Rename on create | N/A (implicit with assignment) | `.alias(\"name\")` |\n| In-place modification | `df[\"col\"] = ...` modifies `df` | `with_columns()` returns new DataFrame |\n\n**Key difference**: Pandas modifies DataFrames in-place by default, while Polars always returns a new DataFrame (immutability).",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conditional Logic: `when().then().otherwise()`\n",
    "\n",
    "This is Polars' equivalent of SQL's `CASE WHEN` or Pandas' `np.where()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create order size categories\n",
    "orders_categorized = orders.with_columns(\n",
    "    pl.when(pl.col(\"total_amount\") >= 500)\n",
    "      .then(pl.lit(\"Large\"))\n",
    "      .when(pl.col(\"total_amount\") >= 100)\n",
    "      .then(pl.lit(\"Medium\"))\n",
    "      .otherwise(pl.lit(\"Small\"))\n",
    "      .alias(\"order_size\")\n",
    ")\n",
    "\n",
    "orders_categorized.select(\"product_name\", \"total_amount\", \"order_size\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count by order size\n",
    "orders_categorized.group_by(\"order_size\").len().sort(\"len\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean flag example\n",
    "orders_flagged = orders.with_columns(\n",
    "    pl.when(pl.col(\"status\").is_in([\"cancelled\", \"returned\"]))\n",
    "      .then(pl.lit(True))\n",
    "      .otherwise(pl.lit(False))\n",
    "      .alias(\"is_problematic\")\n",
    ")\n",
    "\n",
    "# Or simpler:\n",
    "orders_flagged = orders.with_columns(\n",
    "    pl.col(\"status\").is_in([\"cancelled\", \"returned\"]).alias(\"is_problematic\")\n",
    ")\n",
    "\n",
    "orders_flagged.select(\"order_id\", \"status\", \"is_problematic\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Comparison\n",
    "\n",
    "```python\n",
    "# Pandas with np.where (single condition)\n",
    "df[\"is_large\"] = np.where(df[\"amount\"] > 500, \"Large\", \"Small\")\n",
    "\n",
    "# Pandas with np.select (multiple conditions)\n",
    "conditions = [\n",
    "    df[\"amount\"] >= 500,\n",
    "    df[\"amount\"] >= 100\n",
    "]\n",
    "choices = [\"Large\", \"Medium\"]\n",
    "df[\"order_size\"] = np.select(conditions, choices, default=\"Small\")\n",
    "```\n",
    "\n",
    "Polars' `when().then().otherwise()` is more readable and chainable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Groupby and Aggregations\n",
    "\n",
    "The `group_by().agg()` pattern is central to data analysis.\n",
    "\n",
    "### 4.1 Basic Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total revenue by category\n",
    "revenue_by_category = orders.group_by(\"category\").agg(\n",
    "    pl.col(\"total_amount\").sum().alias(\"total_revenue\")\n",
    ").sort(\"total_revenue\", descending=True)\n",
    "\n",
    "revenue_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple aggregations\n",
    "category_stats = orders.group_by(\"category\").agg(\n",
    "    pl.len().alias(\"order_count\"),\n",
    "    pl.col(\"total_amount\").sum().alias(\"total_revenue\"),\n",
    "    pl.col(\"total_amount\").mean().alias(\"avg_order_value\"),\n",
    "    pl.col(\"quantity\").sum().alias(\"items_sold\"),\n",
    "    pl.col(\"customer_id\").n_unique().alias(\"unique_customers\")\n",
    ").sort(\"total_revenue\", descending=True)\n",
    "\n",
    "category_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Multiple Grouping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue by category and status\n",
    "category_status = orders.group_by(\"category\", \"status\").agg(\n",
    "    pl.len().alias(\"count\"),\n",
    "    pl.col(\"total_amount\").sum().alias(\"revenue\")\n",
    ").sort([\"category\", \"revenue\"], descending=[False, True])\n",
    "\n",
    "category_status.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Common Aggregation Functions\n",
    "\n",
    "| Function | Description |\n",
    "|----------|-------------|\n",
    "| `sum()` | Sum of values |\n",
    "| `mean()` | Average |\n",
    "| `median()` | Median |\n",
    "| `min()` | Minimum |\n",
    "| `max()` | Maximum |\n",
    "| `std()` | Standard deviation |\n",
    "| `var()` | Variance |\n",
    "| `count()` | Count non-null |\n",
    "| `len()` | Count all (including null) |\n",
    "| `n_unique()` | Count unique values |\n",
    "| `first()` | First value |\n",
    "| `last()` | Last value |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Product performance\n",
    "product_stats = orders.group_by(\"product_name\").agg(\n",
    "    pl.len().alias(\"times_ordered\"),\n",
    "    pl.col(\"quantity\").sum().alias(\"total_quantity\"),\n",
    "    pl.col(\"total_amount\").sum().alias(\"total_revenue\"),\n",
    "    pl.col(\"total_amount\").mean().alias(\"avg_order_value\"),\n",
    "    pl.col(\"discount\").mean().alias(\"avg_discount\")\n",
    ").sort(\"total_revenue\", descending=True)\n",
    "\n",
    "product_stats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Missing Data: `fill_null()`, `drop_nulls()`, `is_null()`\n",
    "\n",
    "Polars uses `null` for missing values (not `NaN` like Pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls in our data\n",
    "orders.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data with nulls\n",
    "df_with_nulls = pl.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", None, \"Diana\", None],\n",
    "    \"age\": [25, None, 35, None, 45],\n",
    "    \"score\": [85.0, 90.0, None, 75.0, 88.0]\n",
    "})\n",
    "df_with_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls per column\n",
    "df_with_nulls.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where name is null\n",
    "df_with_nulls.filter(pl.col(\"name\").is_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where name is NOT null\n",
    "df_with_nulls.filter(pl.col(\"name\").is_not_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any null\n",
    "df_with_nulls.drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null in specific columns\n",
    "df_with_nulls.drop_nulls(subset=[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill nulls with a value\n",
    "df_filled = df_with_nulls.with_columns(\n",
    "    pl.col(\"name\").fill_null(\"Unknown\"),\n",
    "    pl.col(\"age\").fill_null(pl.col(\"age\").mean()),  # Fill with mean\n",
    "    pl.col(\"score\").fill_null(0.0)\n",
    ")\n",
    "df_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Comparison: Missing Data\n",
    "\n",
    "| Operation | Pandas | Polars |\n",
    "|-----------|--------|--------|\n",
    "| Check null | `df[\"col\"].isna()` | `pl.col(\"col\").is_null()` |\n",
    "| Drop nulls | `df.dropna()` | `df.drop_nulls()` |\n",
    "| Fill nulls | `df.fillna(value)` | `df.fill_null(value)` |\n",
    "| Count nulls | `df.isna().sum()` | `df.null_count()` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sorting with `sort()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by single column (ascending by default)\n",
    "orders.sort(\"total_amount\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort descending\n",
    "orders.sort(\"total_amount\", descending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Pandas Comparison: Sorting\n\n| Operation | Pandas | Polars |\n|-----------|--------|--------|\n| Sort ascending | `df.sort_values(\"col\")` | `df.sort(\"col\")` |\n| Sort descending | `df.sort_values(\"col\", ascending=False)` | `df.sort(\"col\", descending=True)` |\n| Multiple columns | `df.sort_values([\"a\", \"b\"], ascending=[True, False])` | `df.sort([\"a\", \"b\"], descending=[False, True])` |\n| Sort by index | `df.sort_index()` | N/A (no index in Polars) |\n\n**Note**: Polars uses `descending` parameter while Pandas uses `ascending`. The logic is inverted!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by multiple columns\n",
    "orders.sort([\"category\", \"total_amount\"], descending=[False, True]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Combining DataFrames\n",
    "\n",
    "### 7.1 Concatenation with `pl.concat()`"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Pandas Comparison: Concatenation\n\n| Operation | Pandas | Polars |\n|-----------|--------|--------|\n| Vertical (stack rows) | `pd.concat([df1, df2])` | `pl.concat([df1, df2])` |\n| Horizontal (add columns) | `pd.concat([df1, df2], axis=1)` | `pl.concat([df1, df2], how=\"horizontal\")` |\n| Reset index after concat | `pd.concat(...).reset_index(drop=True)` | N/A (no index in Polars) |\n\nThe syntax is similar, but Polars uses `how=\"horizontal\"` instead of `axis=1`.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two sample DataFrames\n",
    "df1 = pl.DataFrame({\"id\": [1, 2], \"value\": [\"a\", \"b\"]})\n",
    "df2 = pl.DataFrame({\"id\": [3, 4], \"value\": [\"c\", \"d\"]})\n",
    "\n",
    "# Vertical concatenation (stack rows)\n",
    "combined = pl.concat([df1, df2])\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal concatenation (add columns)\n",
    "df3 = pl.DataFrame({\"extra\": [10, 20]})\n",
    "pl.concat([df1, df3], how=\"horizontal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Joins with `join()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join orders with customers\n",
    "orders_with_customers = orders.join(\n",
    "    customers,\n",
    "    on=\"customer_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(f\"Original orders: {orders.shape}\")\n",
    "print(f\"With customer info: {orders_with_customers.shape}\")\n",
    "orders_with_customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Pandas Comparison: Joins\n\n| Operation | Pandas | Polars |\n|-----------|--------|--------|\n| Inner join | `df1.merge(df2, on=\"key\", how=\"inner\")` | `df1.join(df2, on=\"key\", how=\"inner\")` |\n| Left join | `df1.merge(df2, on=\"key\", how=\"left\")` | `df1.join(df2, on=\"key\", how=\"left\")` |\n| Right join | `df1.merge(df2, on=\"key\", how=\"right\")` | `df1.join(df2, on=\"key\", how=\"right\")` |\n| Outer join | `df1.merge(df2, on=\"key\", how=\"outer\")` | `df1.join(df2, on=\"key\", how=\"full\")` |\n| Different key names | `df1.merge(df2, left_on=\"a\", right_on=\"b\")` | `df1.join(df2, left_on=\"a\", right_on=\"b\")` |\n\n**Key differences**:\n- Pandas uses `merge()`, Polars uses `join()`\n- Outer join is `how=\"outer\"` in Pandas, `how=\"full\"` in Polars\n- Polars has `semi` and `anti` joins built-in (useful for filtering)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Types\n",
    "\n",
    "| Type | Description |\n",
    "|------|-------------|\n",
    "| `inner` | Only matching rows from both |\n",
    "| `left` | All rows from left, matching from right |\n",
    "| `right` | Matching from left, all from right |\n",
    "| `full` | All rows from both (outer join) |\n",
    "| `cross` | Cartesian product |\n",
    "| `semi` | Rows from left that have match in right |\n",
    "| `anti` | Rows from left that have NO match in right |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis: Revenue by customer tier\n",
    "tier_revenue = orders_with_customers.group_by(\"membership_tier\").agg(\n",
    "    pl.len().alias(\"order_count\"),\n",
    "    pl.col(\"total_amount\").sum().alias(\"total_revenue\"),\n",
    "    pl.col(\"total_amount\").mean().alias(\"avg_order_value\")\n",
    ").sort(\"total_revenue\", descending=True)\n",
    "\n",
    "tier_revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Pandas Comparison: String Operations\n\n| Operation | Pandas | Polars |\n|-----------|--------|--------|\n| Uppercase | `df[\"col\"].str.upper()` | `pl.col(\"col\").str.to_uppercase()` |\n| Lowercase | `df[\"col\"].str.lower()` | `pl.col(\"col\").str.to_lowercase()` |\n| Length | `df[\"col\"].str.len()` | `pl.col(\"col\").str.len_chars()` |\n| Contains | `df[\"col\"].str.contains(\"x\")` | `pl.col(\"col\").str.contains(\"x\")` |\n| Replace | `df[\"col\"].str.replace(\"a\", \"b\")` | `pl.col(\"col\").str.replace(\"a\", \"b\")` |\n| Split | `df[\"col\"].str.split(\",\")` | `pl.col(\"col\").str.split(\",\")` |\n| Get element from split | `df[\"col\"].str.split(\",\").str[0]` | `pl.col(\"col\").str.split(\",\").list.first()` |\n| Extract with regex | `df[\"col\"].str.extract(r\"(\\d+)\")` | `pl.col(\"col\").str.extract(r\"(\\d+)\")` |\n\n**Key difference**: After splitting, Pandas uses `.str[n]` indexing while Polars uses `.list.get(n)` or `.list.first()`/`.list.last()`.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis: Revenue by customer city\n",
    "city_revenue = orders_with_customers.group_by(\"city\").agg(\n",
    "    pl.col(\"customer_id\").n_unique().alias(\"unique_customers\"),\n",
    "    pl.col(\"total_amount\").sum().alias(\"total_revenue\")\n",
    ").sort(\"total_revenue\", descending=True)\n",
    "\n",
    "city_revenue.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. String Operations\n",
    "\n",
    "The `.str` namespace provides string manipulation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common string operations\n",
    "customers_strings = customers.with_columns(\n",
    "    # Uppercase\n",
    "    pl.col(\"first_name\").str.to_uppercase().alias(\"name_upper\"),\n",
    "    \n",
    "    # Lowercase\n",
    "    pl.col(\"city\").str.to_lowercase().alias(\"city_lower\"),\n",
    "    \n",
    "    # String length\n",
    "    pl.col(\"email\").str.len_chars().alias(\"email_length\"),\n",
    "    \n",
    "    # Extract domain from email\n",
    "    pl.col(\"email\").str.split(\"@\").list.last().alias(\"email_domain\")\n",
    ")\n",
    "\n",
    "customers_strings.select(\n",
    "    \"first_name\", \"name_upper\", \"city\", \"city_lower\", \"email\", \"email_length\", \"email_domain\"\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String contains and replace\n",
    "orders.with_columns(\n",
    "    pl.col(\"product_name\").str.contains(\"Smart\").alias(\"is_smart_product\"),\n",
    "    pl.col(\"product_name\").str.replace(\"Smart\", \"Intelligent\").alias(\"renamed_product\")\n",
    ").filter(pl.col(\"is_smart_product\")).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Key Methods Covered\n",
    "\n",
    "| Method | Purpose |\n",
    "|--------|--------|\n",
    "| `filter()` | Select rows based on conditions |\n",
    "| `with_columns()` | Add or modify columns |\n",
    "| `when().then().otherwise()` | Conditional logic |\n",
    "| `group_by().agg()` | Groupby aggregations |\n",
    "| `sort()` | Sort rows |\n",
    "| `join()` | Combine DataFrames by key |\n",
    "| `pl.concat()` | Stack DataFrames |\n",
    "| `drop_nulls()` | Remove rows with nulls |\n",
    "| `fill_null()` | Replace null values |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises\n",
    "\n",
    "Using the `orders` and `customers` DataFrames:\n",
    "\n",
    "1. Find all cancelled orders with total amount > $200\n",
    "2. Create a \"discount_tier\" column: \"High\" if discount >= 15%, \"Low\" if > 0%, \"None\" otherwise\n",
    "3. Calculate the average order value for each combination of category and status\n",
    "4. Find the top 5 customers by total spending (join with customers table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Session Preview\n",
    "\n",
    "In Session 3, we'll explore Polars' most powerful feature: **Lazy Evaluation**\n",
    "- Understanding eager vs lazy execution\n",
    "- Query optimization\n",
    "- Performance benchmarking\n",
    "- Working with large datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}