{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1: Introduction to Polars\n",
    "\n",
    "Welcome to the Advanced Tech Track! In this course, we'll learn **Polars**, a modern DataFrame library that offers significant performance advantages over Pandas.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this session, you will be able to:\n",
    "1. Understand what Polars is and why it's useful\n",
    "2. Create DataFrames and Series in Polars\n",
    "3. Read and write various file formats\n",
    "4. Perform basic data inspection\n",
    "5. Select and transform columns using the expression API\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This course assumes you're familiar with:\n",
    "- Python fundamentals\n",
    "- Pandas basics (DataFrames, Series, filtering, groupby)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Polars?\n",
    "\n",
    "**Polars** is a DataFrame library written in Rust with Python bindings. It's designed for:\n",
    "\n",
    "- **Speed**: Often 10-100x faster than Pandas for large datasets\n",
    "- **Memory efficiency**: Better memory management and lazy evaluation\n",
    "- **Modern API**: Consistent, expressive syntax based on expressions\n",
    "- **Parallel execution**: Automatic parallelization of operations\n",
    "\n",
    "### Why learn Polars?\n",
    "\n",
    "| Aspect | Pandas | Polars |\n",
    "|--------|--------|--------|\n",
    "| Written in | C/Cython | Rust |\n",
    "| Memory model | Eager only | Eager + Lazy |\n",
    "| Parallelization | Manual | Automatic |\n",
    "| Index | Row index | No index |\n",
    "| Missing values | NaN + None | null |\n",
    "| String handling | object dtype | Native strings |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Polars\n",
    "import polars as pl\n",
    "\n",
    "# Check version\n",
    "print(f\"Polars version: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating DataFrames and Series\n",
    "\n",
    "Let's start by creating DataFrames - the core data structure in Polars.\n",
    "\n",
    "### 2.1 Creating a DataFrame from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from a dictionary\n",
    "df = pl.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"Diana\"],\n",
    "    \"age\": [25, 30, 35, 28],\n",
    "    \"city\": [\"New York\", \"Paris\", \"London\", \"Tokyo\"]\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Comparison\n",
    "\n",
    "```python\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"Diana\"],\n",
    "    \"age\": [25, 30, 35, 28],\n",
    "    \"city\": [\"New York\", \"Paris\", \"London\", \"Tokyo\"]\n",
    "})\n",
    "```\n",
    "\n",
    "The syntax is nearly identical! The main difference is `pl.DataFrame` vs `pd.DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series\n",
    "s = pl.Series(\"temperatures\", [22.5, 25.0, 18.3, 30.1, 27.8])\n",
    "print(s)\n",
    "print(f\"\\nData type: {s.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series with different data types\n",
    "dates = pl.Series(\"dates\", [\"2024-01-01\", \"2024-01-02\", \"2024-01-03\"]).str.to_date()\n",
    "print(dates)\n",
    "print(f\"\\nData type: {dates.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Comparison: Series\n",
    "\n",
    "| Operation | Pandas | Polars |\n",
    "|-----------|--------|--------|\n",
    "| Create Series | `pd.Series([1, 2, 3])` | `pl.Series([1, 2, 3])` |\n",
    "| Named Series | `pd.Series([1, 2, 3], name=\"values\")` | `pl.Series(\"values\", [1, 2, 3])` |\n",
    "| Access dtype | `s.dtype` | `s.dtype` |\n",
    "| To datetime | `pd.to_datetime(s)` | `s.str.to_date()` |\n",
    "\n",
    "**Note**: In Polars, the series name comes *first* in the constructor: `pl.Series(\"name\", [values])`, while in Pandas it's a keyword argument: `pd.Series([values], name=\"name\")`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reading and Writing Files\n",
    "\n",
    "Polars supports many file formats. Let's explore the most common ones.\n",
    "\n",
    "### 3.1 Reading CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a CSV file\n",
    "employees = pl.read_csv(\"data/employees.csv\")\n",
    "employees.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Comparison\n",
    "\n",
    "| Operation | Pandas | Polars |\n",
    "|-----------|--------|--------|\n",
    "| Read CSV | `pd.read_csv()` | `pl.read_csv()` |\n",
    "| Read JSON | `pd.read_json()` | `pl.read_json()` |\n",
    "| Read Parquet | `pd.read_parquet()` | `pl.read_parquet()` |\n",
    "| Read Excel | `pd.read_excel()` | `pl.read_excel()` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Writing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "employees.head(10).write_csv(\"data/employees_sample.csv\")\n",
    "\n",
    "# Write to Parquet (efficient columnar format)\n",
    "employees.write_parquet(\"data/employees.parquet\")\n",
    "\n",
    "print(\"Files written successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read back the Parquet file\n",
    "employees_parquet = pl.read_parquet(\"data/employees.parquet\")\n",
    "employees_parquet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Understanding Parquet Format\n",
    "\n",
    "**Parquet** is a columnar storage format designed for efficient data storage and retrieval. Unlike CSV (which stores data row by row), Parquet stores data column by column.\n",
    "\n",
    "#### CSV vs Parquet: How They Store Data\n",
    "\n",
    "```\n",
    "CSV (Row-oriented):          Parquet (Column-oriented):\n",
    "┌────┬─────┬──────┐          ┌────────────────────┐\n",
    "│ id │ name│ sal  │          │ id: 1, 2, 3        │\n",
    "├────┼─────┼──────┤          │ name: A, B, C      │\n",
    "│ 1  │ A   │ 50k  │          │ sal: 50k, 60k, 70k │\n",
    "│ 2  │ B   │ 60k  │          └────────────────────┘\n",
    "│ 3  │ C   │ 70k  │\n",
    "└────┴─────┴──────┘\n",
    "```\n",
    "\n",
    "#### Why Parquet is Better for Analytics\n",
    "\n",
    "| Feature | CSV | Parquet |\n",
    "|---------|-----|---------|\n",
    "| **Storage** | Plain text | Binary, compressed |\n",
    "| **File Size** | Large | 2-10x smaller |\n",
    "| **Data Types** | Lost (everything is text) | Preserved |\n",
    "| **Read Speed** | Must parse text | Direct binary read |\n",
    "| **Column Selection** | Must read entire file | Reads only needed columns |\n",
    "| **Schema** | None (inferred) | Embedded in file |\n",
    "\n",
    "#### When to Use Each Format\n",
    "\n",
    "- **CSV**: Human-readable, data exchange, small datasets, compatibility\n",
    "- **Parquet**: Analytics, large datasets, repeated reads, data pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Performance Comparison: Pandas vs Polars, CSV vs Parquet\n",
    "\n",
    "Let's compare the read performance of different combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# First, let's check file sizes\n",
    "csv_path = \"data/employees.csv\"\n",
    "parquet_path = \"data/employees.parquet\"\n",
    "\n",
    "csv_size = os.path.getsize(csv_path)\n",
    "parquet_size = os.path.getsize(parquet_path)\n",
    "\n",
    "print(\"=== File Size Comparison ===\")\n",
    "print(f\"CSV file:     {csv_size:,} bytes\")\n",
    "print(f\"Parquet file: {parquet_size:,} bytes\")\n",
    "print(f\"Parquet is {csv_size/parquet_size:.1f}x smaller\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark function\n",
    "def benchmark_read(read_func, path, n_runs=10):\n",
    "    \"\"\"Run read operation multiple times and return average time.\"\"\"\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        start = time.time()\n",
    "        df = read_func(path)\n",
    "        times.append(time.time() - start)\n",
    "    return sum(times) / len(times) * 1000  # Return milliseconds\n",
    "\n",
    "# Run benchmarks\n",
    "print(\"=== Read Performance Comparison (10 runs each) ===\\n\")\n",
    "\n",
    "# Pandas CSV\n",
    "pandas_csv_time = benchmark_read(pd.read_csv, csv_path)\n",
    "print(f\"Pandas  + CSV:     {pandas_csv_time:.2f} ms\")\n",
    "\n",
    "# Pandas Parquet\n",
    "pandas_parquet_time = benchmark_read(pd.read_parquet, parquet_path)\n",
    "print(f\"Pandas  + Parquet: {pandas_parquet_time:.2f} ms\")\n",
    "\n",
    "# Polars CSV\n",
    "polars_csv_time = benchmark_read(pl.read_csv, csv_path)\n",
    "print(f\"Polars  + CSV:     {polars_csv_time:.2f} ms\")\n",
    "\n",
    "# Polars Parquet\n",
    "polars_parquet_time = benchmark_read(pl.read_parquet, parquet_path)\n",
    "print(f\"Polars  + Parquet: {polars_parquet_time:.2f} ms\")\n",
    "\n",
    "print(f\"\\n=== Speedup Summary ===\")\n",
    "print(f\"Polars CSV vs Pandas CSV:         {pandas_csv_time/polars_csv_time:.1f}x faster\")\n",
    "print(f\"Polars Parquet vs Pandas Parquet: {pandas_parquet_time/polars_parquet_time:.1f}x faster\")\n",
    "print(f\"Polars Parquet vs Pandas CSV:     {pandas_csv_time/polars_parquet_time:.1f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways: File Formats and Performance\n",
    "\n",
    "1. **Parquet files are smaller** due to efficient binary compression\n",
    "2. **Parquet reads are faster** because:\n",
    "   - No text parsing required\n",
    "   - Data types don't need inference\n",
    "   - Can read only needed columns (projection pushdown)\n",
    "3. **Polars is faster than Pandas** for both CSV and Parquet formats\n",
    "4. **Best combination**: Polars + Parquet for maximum performance\n",
    "\n",
    "**Note on dataset size**: With small files (like our 100-row example), you may see some overhead from Parquet's binary format. The performance benefits become dramatic with larger datasets (10K+ rows). In Session 3, we'll benchmark with 100K rows where the differences are substantial.\n",
    "\n",
    "**Recommendation**: When working with data you'll read multiple times, convert CSV to Parquet:\n",
    "\n",
    "```python\n",
    "# One-time conversion\n",
    "pl.read_csv(\"data.csv\").write_parquet(\"data.parquet\")\n",
    "\n",
    "# Then always read from Parquet\n",
    "df = pl.read_parquet(\"data.parquet\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic Data Inspection\n",
    "\n",
    "Let's explore how to inspect our data in Polars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape: (rows, columns)\n",
    "print(f\"Shape: {employees.shape}\")\n",
    "print(f\"Rows: {employees.height}\")\n",
    "print(f\"Columns: {employees.width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "print(\"Columns:\", employees.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "print(\"Data types:\")\n",
    "print(employees.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema (column name -> data type mapping)\n",
    "employees.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First n rows\n",
    "employees.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last n rows\n",
    "employees.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "employees.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Comparison: Inspection Methods\n",
    "\n",
    "| Operation | Pandas | Polars |\n",
    "|-----------|--------|--------|\n",
    "| Shape | `df.shape` | `df.shape` |\n",
    "| Columns | `df.columns` | `df.columns` |\n",
    "| Data types | `df.dtypes` | `df.dtypes` |\n",
    "| First rows | `df.head()` | `df.head()` |\n",
    "| Last rows | `df.tail()` | `df.tail()` |\n",
    "| Summary | `df.describe()` | `df.describe()` |\n",
    "| Info | `df.info()` | `df.schema` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Column Selection with `select()` and `pl.col()`\n",
    "\n",
    "This is where Polars starts to differ from Pandas. Polars uses an **expression API** for selecting and transforming columns.\n",
    "\n",
    "### 5.1 Basic Column Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single column by name (returns DataFrame)\n",
    "employees.select(\"first_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select multiple columns\n",
    "employees.select(\"first_name\", \"last_name\", \"department\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pl.col() - the expression way\n",
    "employees.select(pl.col(\"first_name\"), pl.col(\"salary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Selecting with Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all columns\n",
    "employees.select(pl.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns that start with a pattern\n",
    "employees.select(pl.col(\"^.*_name$\"))  # Columns ending with '_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns by data type\n",
    "employees.select(pl.col(pl.Int64))  # Only integer columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Comparison: Pattern-Based Selection\n",
    "\n",
    "| Operation | Pandas | Polars |\n",
    "|-----------|--------|--------|\n",
    "| All columns | `df` or `df.loc[:, :]` | `df.select(pl.all())` |\n",
    "| Regex pattern | `df.filter(regex=r\"^.*_name$\")` | `df.select(pl.col(\"^.*_name$\"))` |\n",
    "| By dtype | `df.select_dtypes(include=['int64'])` | `df.select(pl.col(pl.Int64))` |\n",
    "| String columns | `df.select_dtypes(include=['object'])` | `df.select(pl.col(pl.String))` |\n",
    "| Exclude columns | `df.drop(columns=[\"col\"])` | `df.select(pl.all().exclude(\"col\"))` |\n",
    "\n",
    "**Note**: Polars' `pl.col()` accepts regex patterns directly, making pattern-based selection more concise than Pandas' `filter()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all string columns\n",
    "employees.select(pl.col(pl.String))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Comparison: Column Selection\n",
    "\n",
    "| Operation | Pandas | Polars |\n",
    "|-----------|--------|--------|\n",
    "| Single column | `df[\"col\"]` or `df.col` | `df.select(\"col\")` |\n",
    "| Multiple columns | `df[[\"col1\", \"col2\"]]` | `df.select(\"col1\", \"col2\")` |\n",
    "| All columns | `df` | `df.select(pl.all())` |\n",
    "| By dtype | `df.select_dtypes(include=['int64'])` | `df.select(pl.col(pl.Int64))` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Introduction to the Expression API\n",
    "\n",
    "The **expression API** is the heart of Polars and what makes it fundamentally different from Pandas.\n",
    "\n",
    "### What is an Expression?\n",
    "\n",
    "An **expression** in Polars is a *description of a computation*, not the result itself. Think of it like a recipe:\n",
    "- The recipe (expression) describes what to do\n",
    "- The cooking (execution) happens later when you call `.select()`, `.with_columns()`, or `.collect()`\n",
    "\n",
    "This separation allows Polars to:\n",
    "1. **Optimize** the computation before running it\n",
    "2. **Parallelize** operations automatically\n",
    "3. **Reuse** expressions across different contexts\n",
    "\n",
    "### Pandas vs Polars: Mental Model\n",
    "\n",
    "| Aspect | Pandas | Polars |\n",
    "|--------|--------|--------|\n",
    "| Column access | Direct: `df[\"col\"]` returns data | Expression: `pl.col(\"col\")` returns a recipe |\n",
    "| When computed | Immediately | When collected/selected |\n",
    "| Optimization | None (eager) | Query optimization possible |\n",
    "| Reusability | Limited | Expressions can be stored and reused |\n",
    "\n",
    "### 6.1 Basic Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expressions can be stored in variables and reused\n",
    "salary_with_raise = (pl.col(\"salary\") * 1.1).alias(\"salary_raised\")\n",
    "salary_with_bonus = (pl.col(\"salary\") * 1.2).alias(\"salary_with_bonus\")\n",
    "\n",
    "# Use the stored expressions\n",
    "employees.select(\n",
    "    pl.col(\"first_name\"),\n",
    "    pl.col(\"salary\"),\n",
    "    salary_with_raise,\n",
    "    salary_with_bonus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expressions can chain multiple operations\n",
    "employees.select(\n",
    "    pl.col(\"first_name\"),\n",
    "    pl.col(\"salary\"),\n",
    "    (pl.col(\"salary\") / 12).round(2).alias(\"monthly_salary\")  # Chain division and rounding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key difference: pl.col() vs df[\"col\"]\n",
    "\n",
    "# In Pandas, this immediately accesses the data:\n",
    "# pandas_salary = df[\"salary\"]  # Returns actual data (Series)\n",
    "\n",
    "# In Polars, this creates an expression (a recipe):\n",
    "polars_salary_expr = pl.col(\"salary\")  # Returns an expression object\n",
    "print(f\"This is an expression object: {type(polars_salary_expr)}\")\n",
    "print(f\"Expression: {polars_salary_expr}\")\n",
    "\n",
    "# The expression is only evaluated when used in a context like select()\n",
    "result = employees.select(polars_salary_expr)\n",
    "print(f\"\\nAfter select(), we get actual data: {type(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Comparison: Column Access vs Expressions\n",
    "\n",
    "```python\n",
    "# PANDAS - Direct access, immediate execution\n",
    "salary_data = df[\"salary\"]           # Returns Series with actual values\n",
    "doubled = df[\"salary\"] * 2           # Computed immediately\n",
    "df[\"doubled\"] = df[\"salary\"] * 2     # Adds column immediately\n",
    "\n",
    "# POLARS - Expression-based, deferred execution  \n",
    "salary_expr = pl.col(\"salary\")              # Returns expression (recipe)\n",
    "doubled_expr = pl.col(\"salary\") * 2         # Still just an expression\n",
    "df.with_columns((pl.col(\"salary\") * 2).alias(\"doubled\"))  # Executed here\n",
    "```\n",
    "\n",
    "**Key insight**: In Polars, you build up expressions that describe what you want, then execute them all at once. This allows Polars to optimize the entire operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Arithmetic Expressions\n",
    "\n",
    "Polars supports all standard arithmetic operations on expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmetic operations on expressions\n",
    "employees.select(\n",
    "    pl.col(\"first_name\"),\n",
    "    pl.col(\"salary\"),\n",
    "    (pl.col(\"salary\") + 5000).alias(\"salary_plus_5k\"),       # Addition\n",
    "    (pl.col(\"salary\") - 10000).alias(\"salary_minus_10k\"),    # Subtraction\n",
    "    (pl.col(\"salary\") * 2).alias(\"salary_doubled\"),          # Multiplication\n",
    "    (pl.col(\"salary\") / 1000).alias(\"salary_in_thousands\"),  # Division\n",
    "    (pl.col(\"salary\") // 10000).alias(\"salary_10k_brackets\"), # Floor division\n",
    "    (pl.col(\"salary\") % 10000).alias(\"salary_mod_10k\"),      # Modulo\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Comparison: Arithmetic Operations\n",
    "\n",
    "| Operation | Pandas | Polars |\n",
    "|-----------|--------|--------|\n",
    "| Addition | `df[\"col\"] + 5000` | `pl.col(\"col\") + 5000` |\n",
    "| Subtraction | `df[\"col\"] - 1000` | `pl.col(\"col\") - 1000` |\n",
    "| Multiplication | `df[\"col\"] * 2` | `pl.col(\"col\") * 2` |\n",
    "| Division | `df[\"col\"] / 1000` | `pl.col(\"col\") / 1000` |\n",
    "| Floor division | `df[\"col\"] // 10` | `pl.col(\"col\") // 10` |\n",
    "| Modulo | `df[\"col\"] % 10` | `pl.col(\"col\") % 10` |\n",
    "| Round | `df[\"col\"].round(2)` | `pl.col(\"col\").round(2)` |\n",
    "| Absolute | `df[\"col\"].abs()` | `pl.col(\"col\").abs()` |\n",
    "\n",
    "The operators are identical! The difference is that Pandas operates on data directly, while Polars builds an expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Aggregation Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute aggregations\n",
    "employees.select(\n",
    "    pl.col(\"salary\").mean().alias(\"avg_salary\"),\n",
    "    pl.col(\"salary\").min().alias(\"min_salary\"),\n",
    "    pl.col(\"salary\").max().alias(\"max_salary\"),\n",
    "    pl.col(\"salary\").std().alias(\"std_salary\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values\n",
    "employees.select(\n",
    "    pl.col(\"department\").n_unique().alias(\"unique_departments\"),\n",
    "    pl.col(\"position\").n_unique().alias(\"unique_positions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Comparison: Aggregation Functions\n",
    "\n",
    "| Operation | Pandas | Polars |\n",
    "|-----------|--------|--------|\n",
    "| Mean | `df[\"col\"].mean()` | `pl.col(\"col\").mean()` |\n",
    "| Sum | `df[\"col\"].sum()` | `pl.col(\"col\").sum()` |\n",
    "| Min | `df[\"col\"].min()` | `pl.col(\"col\").min()` |\n",
    "| Max | `df[\"col\"].max()` | `pl.col(\"col\").max()` |\n",
    "| Std | `df[\"col\"].std()` | `pl.col(\"col\").std()` |\n",
    "| Count | `df[\"col\"].count()` | `pl.col(\"col\").count()` |\n",
    "| Unique count | `df[\"col\"].nunique()` | `pl.col(\"col\").n_unique()` |\n",
    "| First | `df[\"col\"].iloc[0]` | `pl.col(\"col\").first()` |\n",
    "| Last | `df[\"col\"].iloc[-1]` | `pl.col(\"col\").last()` |\n",
    "\n",
    "**Key difference**: In Pandas, these return a scalar value. In Polars, they return expressions that can be combined with other expressions in a single `select()` call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 String Expressions\n",
    "\n",
    "Both Pandas and Polars provide a `.str` accessor (also called a \"namespace\") for string operations. This is one area where the two libraries are conceptually similar, but with important differences.\n",
    "\n",
    "#### What is the `.str` Namespace?\n",
    "\n",
    "The `.str` namespace is a collection of string methods that can be applied to text data. Instead of writing `upper(column)`, you write `column.str.to_uppercase()`. This keeps all string operations organized under one umbrella.\n",
    "\n",
    "#### Similarities Between Pandas and Polars `.str`\n",
    "\n",
    "| Aspect | Both Libraries |\n",
    "|--------|----------------|\n",
    "| Access pattern | Use `.str.method_name()` syntax |\n",
    "| Chaining | Methods can be chained: `.str.lower().str.strip_chars()` |\n",
    "| Vectorized | Operations apply to all values at once (no loops needed) |\n",
    "| Null handling | Both handle null/NaN values gracefully |\n",
    "\n",
    "#### Key Differences\n",
    "\n",
    "| Aspect | Pandas `.str` | Polars `.str` |\n",
    "|--------|---------------|---------------|\n",
    "| **Applied to** | Series directly: `df[\"col\"].str.upper()` | Expressions: `pl.col(\"col\").str.to_uppercase()` |\n",
    "| **Execution** | Immediate | Deferred (part of expression) |\n",
    "| **Method names** | Shorter: `upper()`, `lower()`, `len()` | More explicit: `to_uppercase()`, `to_lowercase()`, `len_chars()` |\n",
    "| **Return type** | Series (data) | Expression (recipe) |\n",
    "| **After split** | Index with `.str[0]` | Use `.list.first()` or `.list.get(0)` |\n",
    "\n",
    "#### Why Polars Uses Different Names\n",
    "\n",
    "Polars chose more explicit method names to avoid ambiguity:\n",
    "\n",
    "- `len()` vs `len_chars()`: In Polars, `len_chars()` counts characters, while `len_bytes()` counts bytes. This matters for Unicode text (e.g., \"café\" has 4 characters but 5 bytes in UTF-8).\n",
    "- `upper()` vs `to_uppercase()`: The `to_` prefix makes it clear a transformation is happening.\n",
    "- `startswith()` vs `starts_with()`: Polars uses snake_case consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String operations via .str namespace\n",
    "employees.select(\n",
    "    pl.col(\"first_name\"),\n",
    "    pl.col(\"first_name\").str.to_uppercase().alias(\"name_upper\"),\n",
    "    pl.col(\"first_name\").str.len_chars().alias(\"name_length\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine first and last name\n",
    "employees.select(\n",
    "    pl.col(\"first_name\"),\n",
    "    pl.col(\"last_name\"),\n",
    "    (pl.col(\"first_name\") + \" \" + pl.col(\"last_name\")).alias(\"full_name\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Comparison: String Operations\n",
    "\n",
    "| Operation | Pandas | Polars |\n",
    "|-----------|--------|--------|\n",
    "| Uppercase | `df[\"col\"].str.upper()` | `pl.col(\"col\").str.to_uppercase()` |\n",
    "| Lowercase | `df[\"col\"].str.lower()` | `pl.col(\"col\").str.to_lowercase()` |\n",
    "| Length | `df[\"col\"].str.len()` | `pl.col(\"col\").str.len_chars()` |\n",
    "| Contains | `df[\"col\"].str.contains(\"x\")` | `pl.col(\"col\").str.contains(\"x\")` |\n",
    "| Replace | `df[\"col\"].str.replace(\"a\", \"b\")` | `pl.col(\"col\").str.replace(\"a\", \"b\")` |\n",
    "| Split | `df[\"col\"].str.split(\",\")` | `pl.col(\"col\").str.split(\",\")` |\n",
    "| Strip whitespace | `df[\"col\"].str.strip()` | `pl.col(\"col\").str.strip_chars()` |\n",
    "| Starts with | `df[\"col\"].str.startswith(\"x\")` | `pl.col(\"col\").str.starts_with(\"x\")` |\n",
    "| Ends with | `df[\"col\"].str.endswith(\"x\")` | `pl.col(\"col\").str.ends_with(\"x\")` |\n",
    "| Concatenate | `df[\"a\"] + \" \" + df[\"b\"]` | `pl.col(\"a\") + \" \" + pl.col(\"b\")` |\n",
    "\n",
    "**Note**: Polars uses `to_uppercase()`/`to_lowercase()` instead of `upper()`/`lower()`, and `len_chars()` instead of `len()` (to distinguish from byte length)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Boolean and Comparison Expressions\n",
    "\n",
    "Boolean expressions are essential for filtering (covered in Session 2) and conditional logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison expressions return boolean values\n",
    "employees.select(\n",
    "    pl.col(\"first_name\"),\n",
    "    pl.col(\"salary\"),\n",
    "    (pl.col(\"salary\") > 100000).alias(\"high_earner\"),\n",
    "    (pl.col(\"salary\") >= 80000).alias(\"above_80k\"),\n",
    "    (pl.col(\"department\") == \"Engineering\").alias(\"is_engineering\"),\n",
    "    (pl.col(\"department\") != \"Sales\").alias(\"not_sales\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining boolean expressions with AND (&) and OR (|)\n",
    "employees.select(\n",
    "    pl.col(\"first_name\"),\n",
    "    pl.col(\"department\"),\n",
    "    pl.col(\"salary\"),\n",
    "    # AND: both conditions must be true\n",
    "    ((pl.col(\"department\") == \"Engineering\") & (pl.col(\"salary\") > 100000)).alias(\"eng_high_earner\"),\n",
    "    # OR: either condition can be true\n",
    "    ((pl.col(\"department\") == \"Sales\") | (pl.col(\"department\") == \"Marketing\")).alias(\"sales_or_marketing\"),\n",
    "    # NOT: negate a condition\n",
    "    (~(pl.col(\"is_active\"))).alias(\"is_inactive\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Comparison: Boolean and Comparison Operations\n",
    "\n",
    "| Operation | Pandas | Polars |\n",
    "|-----------|--------|--------|\n",
    "| Equal | `df[\"col\"] == value` | `pl.col(\"col\") == value` |\n",
    "| Not equal | `df[\"col\"] != value` | `pl.col(\"col\") != value` |\n",
    "| Greater than | `df[\"col\"] > value` | `pl.col(\"col\") > value` |\n",
    "| Less than | `df[\"col\"] < value` | `pl.col(\"col\") < value` |\n",
    "| Greater or equal | `df[\"col\"] >= value` | `pl.col(\"col\") >= value` |\n",
    "| Less or equal | `df[\"col\"] <= value` | `pl.col(\"col\") <= value` |\n",
    "| AND | `(cond1) & (cond2)` | `(cond1) & (cond2)` |\n",
    "| OR | `(cond1) \\| (cond2)` | `(cond1) \\| (cond2)` |\n",
    "| NOT | `~condition` | `~condition` |\n",
    "| Is null | `df[\"col\"].isna()` | `pl.col(\"col\").is_null()` |\n",
    "| Is not null | `df[\"col\"].notna()` | `pl.col(\"col\").is_not_null()` |\n",
    "| Is in list | `df[\"col\"].isin([...])` | `pl.col(\"col\").is_in([...])` |\n",
    "| Between | `df[\"col\"].between(a, b)` | `pl.col(\"col\").is_between(a, b)` |\n",
    "\n",
    "**Important**: Always wrap conditions in parentheses when using `&` and `|` due to Python's operator precedence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Creating New Columns with `with_columns()`\n",
    "\n",
    "To add new columns to an existing DataFrame, use `with_columns()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns\n",
    "employees_enhanced = employees.with_columns(\n",
    "    # Annual bonus (10% of salary)\n",
    "    (pl.col(\"salary\") * 0.10).alias(\"bonus\"),\n",
    "    \n",
    "    # Full name\n",
    "    (pl.col(\"first_name\") + \" \" + pl.col(\"last_name\")).alias(\"full_name\"),\n",
    "    \n",
    "    # Uppercase department\n",
    "    pl.col(\"department\").str.to_uppercase().alias(\"department_upper\")\n",
    ")\n",
    "\n",
    "employees_enhanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Comparison\n",
    "\n",
    "```python\n",
    "# Pandas way (modifies in place or requires copy)\n",
    "df[\"bonus\"] = df[\"salary\"] * 0.10\n",
    "df[\"full_name\"] = df[\"first_name\"] + \" \" + df[\"last_name\"]\n",
    "\n",
    "# Or with .assign() (returns new DataFrame)\n",
    "df = df.assign(\n",
    "    bonus=df[\"salary\"] * 0.10,\n",
    "    full_name=df[\"first_name\"] + \" \" + df[\"last_name\"]\n",
    ")\n",
    "```\n",
    "\n",
    "Polars' `with_columns()` always returns a new DataFrame, promoting immutability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Differences from Pandas\n",
    "\n",
    "### No Index\n",
    "Polars doesn't have a row index. This simplifies many operations and avoids index alignment issues.\n",
    "\n",
    "### Expressions vs Direct Operations\n",
    "Polars encourages using expressions (`pl.col()`) rather than direct column access.\n",
    "\n",
    "### Immutability\n",
    "Polars operations return new DataFrames rather than modifying in place.\n",
    "\n",
    "### Strict Typing\n",
    "Polars is stricter about data types, which helps catch errors early."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Pandas to Polars Cheat Sheet\n",
    "\n",
    "| Operation | Pandas | Polars |\n",
    "|-----------|--------|--------|\n",
    "| Import | `import pandas as pd` | `import polars as pl` |\n",
    "| Create DataFrame | `pd.DataFrame({...})` | `pl.DataFrame({...})` |\n",
    "| Read CSV | `pd.read_csv(\"file.csv\")` | `pl.read_csv(\"file.csv\")` |\n",
    "| Write CSV | `df.to_csv(\"file.csv\")` | `df.write_csv(\"file.csv\")` |\n",
    "| Select columns | `df[[\"col1\", \"col2\"]]` | `df.select(\"col1\", \"col2\")` |\n",
    "| Add column | `df[\"new\"] = expr` | `df.with_columns(expr.alias(\"new\"))` |\n",
    "| Column reference | `df[\"col\"]` | `pl.col(\"col\")` |\n",
    "| Rename | `df.rename(columns={...})` | `df.rename({...})` |\n",
    "| Shape | `df.shape` | `df.shape` |\n",
    "| Data types | `df.dtypes` | `df.dtypes` or `df.schema` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises\n",
    "\n",
    "Try these exercises using the `employees` DataFrame:\n",
    "\n",
    "1. Select only the `position` and `salary` columns\n",
    "2. Create a new column `monthly_salary` that divides `salary` by 12\n",
    "3. Create a column `email_domain` that extracts \"company.com\" from the email addresses\n",
    "4. Calculate the average, min, and max salary in a single `select()` statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Select position and salary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Create monthly_salary column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Extract email domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Calculate salary statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Session Preview\n",
    "\n",
    "In Session 2, we'll dive deeper into:\n",
    "- Filtering rows with `filter()`\n",
    "- Conditional logic with `when().then().otherwise()`\n",
    "- Groupby operations and aggregations\n",
    "- Joining DataFrames\n",
    "- Handling missing data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "att-mbads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
